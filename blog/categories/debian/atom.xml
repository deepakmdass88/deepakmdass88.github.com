<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: debian | Welcome to My Nerd World]]></title>
  <link href="http://beingasysadmin.com/blog/categories/debian/atom.xml" rel="self"/>
  <link href="http://beingasysadmin.com/"/>
  <updated>2015-02-06T10:23:38+00:00</updated>
  <id>http://beingasysadmin.com/</id>
  <author>
    <name><![CDATA[Deepak Mohandas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Managing Debian APT repository via Aptly]]></title>
    <link href="http://beingasysadmin.com/blog/2014/12/07/managing-debian-apt-repository-via-aptly/"/>
    <updated>2014-12-07T07:04:00+00:00</updated>
    <id>http://beingasysadmin.com/blog/2014/12/07/managing-debian-apt-repository-via-aptly</id>
    <content type="html"><![CDATA[<p>In my previous <a href="https://beingasysadmin.wordpress.com/2014/12/03/building-a-debian-package/">blog</a>, i've explained how to build a Debian pacakge from source. In this blog i'm to explain how to create and manage our own apt repository. Enter <a href="aptly.info">aptly</a>,is a swiss army knife for Debian repository management: it allows us to mirror remote repositories, manage local package repositories, take snapshots, pull new versions of packages along with dependencies, publish as Debian repository. Aptly can upload the repo to Amazon S3, but we need to install APT S3 <a href="https://github.com/castlabs/apt-s3">support</a>, in order to use it from S3.</p>

<p>First, let's install aptly on our build server. A more detailed documentation on installation is available in the <a href="http://www.aptly.info/download/">website</a></p>

<pre><code>$ echo "deb http://repo.aptly.info/ squeeze main" &gt; /etc/apt/sources.list

$ gpg --keyserver keys.gnupg.net --recv-keys 2A194991

$ gpg -a --export 2A194991 | sudo apt-key add -

$ apt-get update &amp;&amp; apt-get install aptly
</code></pre>

<p>Let's create a repo,</p>

<pre><code>$ aptly repo create -distribution=wheezy -component=main my-repo    # where my-repo is the name of the repository
</code></pre>

<p>Once the repo is created, we can start adding our newly created packages to our new repo.</p>

<pre><code>$ aptly repo add &lt;repo name&gt; &lt;your debian file&gt;    # in my case aptly repo add myrepo openvpn_2.3.6_amd64.deb
</code></pre>

<p>The above command will add the new package to the repo. Now in order to make this repo usable, we need to publish this repo. A valid GPG key is required for publishing the repo. So let's create the gpg key for aptly.</p>

<pre><code>$ gpg --gen-key

$ gpg --export --armor &lt;email-id-used-fo-gpg-key-creation&gt; &gt; myrepo-pubkey.asc   # creates a pubkey that distributed

$ gpg --send-key KEYNAME     # This command can be used if we want to send the key to a public server, we can also pass --keyserver &lt;server-url&gt;, if we want to specifiy a specific keyserver
</code></pre>

<p>Once we have our GPG key, we can publish our repo. By default aptly can publish the repo to S3 or it can publish it locally and we can use any webserver to servce this repo.</p>

<pre><code>$ aptly publish --distribution="wheezy" repo my-repo
</code></pre>

<p>Once published, we can point the webserver to "~/.aptly/", where our repo files will be created. Aptly also comes with an embedded webserver which can be invoked by running <code>aptly serve</code>. Aptly really makes the repo management so easy. We can actually integrate this into our jenkins job so that each time when we build a package, we can directly add and upload the same to our repository.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Debian packages]]></title>
    <link href="http://beingasysadmin.com/blog/2014/12/03/building-debian-packages/"/>
    <updated>2014-12-03T22:32:00+00:00</updated>
    <id>http://beingasysadmin.com/blog/2014/12/03/building-debian-packages</id>
    <content type="html"><![CDATA[<p>Installing applications via packages saves us a lot of time. Especially being an OPS oriented guy, compiling applications from source is somtimes pain and time consuming. Especially the dependencies. But later, after the rise of config management system, people started creating corresponding automated scripts that will install necessary dependencies and the ususal <code>make &amp;&amp; make install</code>. But if you check applications like Freeswitch was taking 15+min to finish compiliations, which is defintely a bad idea when you want to deploy the a new patch on a cluster. In such cases packages are really a life saver. Build the packages once as per our requirement and deploy it throughout the infrastructure. Now with the tools like jenkins,TravisCI etc we can attain a good level of CI.</p>

<p>In this blog, i'm going to explain on how to build a debian package from scratch. First let's install two main dependencies for a build machine</p>

<pre><code>$ apt-get install devscripts build-essential
</code></pre>

<p>For the past few days i was playing with <em>OpenVPN</em> and <em>SoftEther</em>. I'm going to build a simple debian package for OpenVPN from source. The current stable version of OpenVPN is available 2.3.6. First let's get the OpenVPN source code.</p>

<pre><code>$ wget http://swupdate.openvpn.org/community/releases/openvpn-2.3.6.tar.gz

$ tar xvzf openvpn-2.3.6.tar.gz &amp;&amp; cd openvpn-2.3.6
</code></pre>

<p>Now for building a package, first we need to create a <code>debian</code> folder. And in this folder we are going to place all necessary files required for building a package.</p>

<pre><code>$ mkdir debian
</code></pre>

<p>As per the Debian pacakging <a href="https://www.debian.org/doc/manuals/maint-guide/dreq.en.html">Documentation</a>, the mandatory files are <a href="https://www.debian.org/doc/manuals/maint-guide/dreq.en.html#rules">rules</a> <a href="https://www.debian.org/doc/manuals/maint-guide/dreq.en.html#control">control</a>, <a href="https://www.debian.org/doc/manuals/maint-guide/dreq.en.html#changelog">changelog</a>. <code>Changlog</code> file content should match the exact syntax, otherwise packaging will fail at the initial stage itself. There are some more optional files that we can <a href="https://www.debian.org/doc/manuals/maint-guide/dother.en.html">use</a>. Below are the files present in my <code>debian</code> folder</p>

<pre><code>changelog           =&gt; Changelog for my Package
control             =&gt; Contains Details about the package including the dependencies
dirs                =&gt; specifies any directories which we need but which are not created by the normal installation procedure, handled by 'dh_installdirs'
openvpn.default     =&gt; this file will be copied to /etc/default/openvpn
openvpn.init        =&gt; this file will be copied to /etc/init.d/openvpn, handled by 'dh_installinit'
postinst.debhelper  =&gt; Any action that need to be performed once the package installation is completed, like creating a specific user, starting service etc
postrm.debhelper        =&gt; Any action that need to be performed once the package removal is completed, like deleting a specific user
prerm.debhelper     =&gt; Any action that need to be performed before the package removal is initiated, like stopping the service
rules           =&gt; Contains rules for build procedure
</code></pre>

<p>In my case i wanted to install the openvpn on a custom location say '<strong>/opt/openvpn</strong>'. So if we are building from scratch manually, we can mention the prefix like '<strong>./configure --prefix=/opt/openvpn</strong>'. but in the build process, <code>dh_auto_configure</code> is running our '<strong>./configure</strong>' operation with dfault option ie, no custom prefix. So we need to overide this process if we want to have a custom prefix. Below is the content of my <code>rules</code> file.</p>

<pre><code># rules file

    #!/usr/bin/make -f
    # vim: tabstop=4 softtabstop=4 noexpandtab fileencoding=utf-8

    # Uncomment this to turn on verbose mode.
    export DH_VERBOSE=1

    DEB_DIR=$(CURDIR)/debian/openvpn

    %:
        dh $@
    override_dh_auto_configure:                      # override of configure
        ./configure --prefix=/opt/openvpn
</code></pre>

<p>Once we have all the necessary files in place, we can start the build process. Make sure that all the dependency packages mentioned in the <code>control</code> file is installed on the build server.</p>

<pre><code>    $ debuild -us -uc
</code></pre>

<p>If the build command is completed successfully, we will see the deb package as well as the source package just above our openvpn source folderm which is the default path where <code>dh_builddeb</code> places the files. We can overide the same too.</p>

<pre><code>#!/usr/bin/make -f
# vim: tabstop=4 softtabstop=4 noexpandtab fileencoding=utf-8

# Uncomment this to turn on verbose mode.
export DH_VERBOSE=1

DEB_DIR=$(CURDIR)/debian/openvpn

%:
    dh $@
override_dh_auto_configure:
    ./configure --prefix=/opt/openvpn
override_dh_builddeb:
    dh_builddeb --destdir=./deb-pkg/
</code></pre>

<p>So now we have the Debian package. We can test installing it manually via '<strong>dpkg -i</strong>'. This was just a go thorugh on how to build a simple debian package. In my next blog, i'll be discussing about how to create and manage a private apt repository using a awsme tool called <a href="http://www.aptly.info/">aptly</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Virtualization using Linux Containers]]></title>
    <link href="http://beingasysadmin.com/blog/2013/03/19/virtualiation-using-linux-containers/"/>
    <updated>2013-03-19T23:18:00+00:00</updated>
    <id>http://beingasysadmin.com/blog/2013/03/19/virtualiation-using-linux-containers</id>
    <content type="html"><![CDATA[<p><strong>LXC</strong> or <strong>Linux Continers</strong> is is an operating system-level virtualization, using which we can run multiple isolated Linux systems on a single host.  LXC relies on the <a href="http://en.wikipedia.org/wiki/Cgroups">cgroups</a> functionality of the Linux Kernels. <em>Cgroups (control groups)</em> is a Linux kernel feature to limit, account and isolate resource usage (CPU, memory, disk I/O, etc.) of process groups. LXC does not provide a virtual machine, but rather provides a virtual environment that has its own process and network space. It is similar to a chroot, but offers much more isolation.</p>

<p>First, let's install the necessary packages.</p>

<pre><code>$ apt-get install lxc btrutils
</code></pre>

<p>By default in Ubuntu, when we install the lxc package, it will create a default bridge network called "lxcbr0". If we don't want to use this bridge network, we can disbale it by editing the <code>/etc/default/lxc</code> file. We can also create bridge networks using the <strong><em>"btrcl"</em></strong> or we can directly define the bridge networks in the interfaces file. There are a few templates, which gts shipped with the lxc package, which will be present in the <code>/usr/share/lxc/template</code>. I'm going to use the default template to create the containers. We can also use OPENVZ templates to create containers.</p>

<p>I'm going to keep my keep all my container's files in a default path say "/lxc"</p>

<pre><code>$ mkdir /lxc
</code></pre>

<p>Now we can create the first debian container.</p>

<pre><code>$ mkdir /lxc/vm0    # where vm0 is the name of my conatiner.

$ /usr/share/lxc/templates/lxc-debian -p /lxc/vm0
</code></pre>

<p>Now this will install and build the necessary files for the container. If we go inside the vm0 folder, we can see two things, one is the config file, and second is the root folder of the container. This root folder will be the virtual environment for our container. Now we can edit the config file, to mention the default Network options.</p>

<pre><code>lxc.network.ipv4 = 192.168.0.123/24 # IP address should end with CIDR
lxc.network.hwaddr = 4a:59:43:49:79:bf # MAC address
lxc.network.link = br0 # name of the bridge interface
lxc.network.type = veth 
lxc.network.veth.pair = veth_vm0
</code></pre>

<p>Now we need to add the ip to the lxc's interface file alos, for that we need to edit the <code>/lxc/vm0/rootfs/etc/network/interfaces</code> file and set the ip address in it for the interface <em>eth0</em>
We can create a bridge interface and we can bind it with the physical interface of the host, so that the lxc will be in the same network as that of the host. If there is a virtual network already existing, for example, when we install libvirt, it will create a bridge interface called "virbr0", or in Ubuntu the lxc package installation wil create a bridge interface called 'lxcbr0', we can alos use those with lxc. Or we can define a bridge interface in the "interfaces" file. Below is a configuration of creating a bridge interface.</p>

<pre><code>    auto eth0
    iface eth0 inet manual

# Bridge setup
    iface br0 inet static
        bridge_ports eth0 
        address 192.168.0.2
        broadcast 192.168.0.255
        netmask 255.255.255.0
        gateway 192.168.0.1
</code></pre>

<p>If a separate network has to be given for the lxc's, then we can to go for NATing. The below configuration on the interfaces file is for the NAT enabled.</p>

<pre><code>auto br0
iface br0 inet static
address 172.16.0.1
netmask 255.255.255.0
bridge_stp off
bridge_maxwait 5
pre-up  /usr/sbin/brctl addbr br0
post-up /usr/sbin/brctl setfd br0 0
post-up /sbin/iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
post-up echo 1 &gt; /proc/sys/net/ipv4/ip_forward
</code></pre>

<p>Once we are ready with the configurations, we can start our container using the below command.</p>

<pre><code>$ lxc-start -n vm0 -f /lxc/vm0/config
</code></pre>

<p>In the NAT scenario, the lxc machines are under the "172.16" network, while the host lies in "192.168.0" network. There are some good projects which works around with lxc, <a href="https://github.com/chrisroberts/vagabond">vagabond</a> is an example for that.Vagabond is a tool integrated with Chef to build local nodes easily and most importantly, quickly. Vagabond is built for Chef.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Foreman with Puppet and Libvirt]]></title>
    <link href="http://beingasysadmin.com/blog/2013/03/07/using-foreman-with-puppet-and-libvirt/"/>
    <updated>2013-03-07T09:39:00+00:00</updated>
    <id>http://beingasysadmin.com/blog/2013/03/07/using-foreman-with-puppet-and-libvirt</id>
    <content type="html"><![CDATA[<p><em>TheForeman</em> is one of the best provisioning tools available. It's purely open-sourced. And it natively supports <strong><em>puppet</em></strong> for provisioning the nodes. Foreman can talk to <strong>libvirt</strong> also, which makes us easy to create a VM and provision it on the way. In this blog i will be explaining on how to install Foreman from the source, how to integrate it with puppet to receive the logs and facts and make Foreman to use Libvirt for building VM's.</p>

<h3>Setting up Foreman</h3>


<p>First will install the basic depenencies. Since i'm using the git repository of Foreman for installation, git package has to be installed. Moreover we also need a database for Foreman. I'm going to use Mysql for that.</p>

<pre><code>$ apt-get install git mysql-server ruby-mysql libmysql-ruby1.9.1 libmysqlclient-dev libvirt-dev 
</code></pre>

<p>Now clone the repository from github. The newer build's works with <em>Puppet 3.0</em>.</p>

<pre><code>$ git clone https://github.com/theforeman/foreman.git -b develop
</code></pre>

<p>Ensure that "<strong><em>ruby</em></strong> and <strong><em>bundler</em></strong>" is installed in the machine.</p>

<pre><code>$ bundle install --without postgresql sqlite
</code></pre>

<p>Now we can start configuring Foreman. Copy the sample config files.</p>

<pre><code>$ cp config/settings.yaml.example config/settings.yaml
$ cp config/database.yml.example config/database.yml
</code></pre>

<p>Now create a database for FOreman and add the database details in the <code>database.yml</code>. Now add the puppet master details in the <code>settings.yaml</code>. Since i'm going to use the Foreman in production mode, i've commented out the Development and test environment setting in <code>database.yml</code>. Once the config files are set, we can now go ahead with db migration.</p>

<pre><code>$ RAILS_ENV=production bundle exec rake db:migrate
</code></pre>

<p>Now we can check whether the server is fine or not by using the following command. The below command will start the Foreman with the builtin web server, and we can access the webui from <code>http://foreman_ip:3000</code> in the browser. By default there is no authentication set for the WebUI. But LDAP Authentication can be set for the WebUI. Details are availabe in the foreman's <a href="http://theforeman.org/manuals/1.1/index.html#4.1WebInterface">documentation</a>.</p>

<pre><code>$ RAILS_ENV=production rails server
</code></pre>

<p>Once the Foreman server is working fine, we can configure puppet to send its logs and facts to foreman. In the puppet clients, add <code>report = true</code> in the puppet.conf file. Now in the puppet master, we need to do a few stuffs.</p>

<p>Copy this foreman <a href="https://raw.github.com/theforeman/puppet-foreman/master/templates/foreman-report.rb.erb">report</a> file to puppet's report library.</p>

<p>In my case it is <code>/usr/lib/ruby/vendor_ruby/puppet/reports/</code> and rename it to foreman.rb. Now add <code>reports=log, foreman</code> in the <strong><em>puppet.conf</em></strong> file. Also add the foreman url in the foreman.rb file.</p>

<pre><code>foreman_url='http://foreman:3000    # or use ip instead of foreman, if DNS/Host entry is not there for Foreman
</code></pre>

<p>Now for sending facts to puppet, we can put a cron job to execute the below command</p>

<pre><code>$ rake puppet:import:hosts_and_facts RAILS_ENV=production
</code></pre>

<p>Now once the puppet clients starts running, they will send the logs to Foreman, and can be viewed in the WebUI.</p>

<h3>Foreman and Libvirt</h3>


<p>Now in the same machine i've installed libvirt and libvirt-ruby. Now create a user "foreman" and generate ssh-key for the user. Now copy the public key to the "authorized_keys" file of the root user. This is actually needed if your libvirt host is different.</p>

<p>Now go to the Foreman WebUI, Go to  <strong><em>More</em></strong> -----> <strong><em>provisioning</em></strong> -----> <strong><em>Compute Resources</em></strong>. Now click on "New Compute Resource", Add a name for the Resource, Select the provider as <em>Libvirt</em>, and URL is <code>qemu:///system</code>, since libvirt and foreman resides on the same system. We can also test the connection to libvirt. IF the parameters we entered are fine, Foreman can talk to libvirt directly.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using SNMP with Icinga]]></title>
    <link href="http://beingasysadmin.com/blog/2013/02/26/using-snmp-with-icinga/"/>
    <updated>2013-02-26T21:55:00+00:00</updated>
    <id>http://beingasysadmin.com/blog/2013/02/26/using-snmp-with-icinga</id>
    <content type="html"><![CDATA[<p>In my previous i explained how to set up the Icinga monitoring system on Debian based machine. In this i will be explaining on how to use SNMP with icinga. Using SNMP we can get various info from a remote machine which can be used to icinga.</p>

<p>On the remote server we need to install the snmp server. In ordr to check whether the snmp is working fine, we can install the snmp client also on the same machine.</p>

<pre><code>apt-get install snmp snmp-server
</code></pre>

<p>From Debian Wheezy onwards, the <strong><em>snmp-mibs</em></strong> package has been removed from the debian repositories. But we can download the debian file from the squeeze repo. Since it has only a few depenencies and they can be installed from the debian repositories, we can manually install the mibs package. But in Ubuntu mibs package is still available in their repositories.</p>

<p>Once the package is installed we can run the <strong><em>download-mibs</em></strong> to install all the necessary mibs. Now once the snmpd package is installed, we need to comment the MIBS option in the <code>/etc/snmp/snmp.conf</code>. And define the basic settings like, location, contact etc in the <code>snmpd.conf</code> file. We can define the ip to which snmp should listen either in the snmpd.conf file or in the <code>/etc/default/snmp</code> file as an extra option. Once the settings are modified, we can start the snmpd service.</p>

<p> So now the service will listening on the port <em>631</em> on the ip which we defined, by default <strong>127.0.0.1</strong>. We can also enable authentication for snmp service, so that the snmp clients which passes the authentication will be able to get the result from the snmp service.</p>

<p>Once the snmp service has started on the remote server, we can test the snmp onnectivity from our icinga server using the nagios' <code>check_snmp plugin</code>. Once we are able to get results from the snmp service, we can deploy tese snmp services into our icinga host configurations to get the results from the remote server's using the <strong><em>check_snmp command</em></strong>.</p>
]]></content>
  </entry>
  
</feed>
