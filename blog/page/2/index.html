

<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Welcome to My Nerd World</title>
  <meta name="author" content="Deepak M Das">
  <link rel="author" href="humans.txt">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  
    
  
  <meta name="description" content=" ">
  
  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://beingasysadmin.com/blog/page/2/">
  <link href="/favicon.png" rel="icon">
  <link href='http://fonts.googleapis.com/css?family=Cantarell' rel='stylesheet' type='text/css'>
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Welcome to My Nerd World" type="application/atom+xml">
  <meta name="og:type" content="website" />
  <meta name="og:site_name" content="Welcome to My Nerd World" />
  <meta name="og:title" content="Welcome to My Nerd World" />
  <meta name="og:description" content=" " />
  <meta name="og:url" content="http://beingasysadmin.com/blog/page/2/index.html"/>
  <meta name="url" content="http://beingasysadmin.com/blog/page/2/index.html">
  
  <meta name="distribution" content="global">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <div id="front-wrapper">
  <div id="hero">
    <div id="hero-inner" class="container">
      <div class="span10 offset1">
  <h1>
    I&#8217;m <em>Deepak</em>,<br/>
    a <em>Random Sys Admin</em><br/>
    by <em>Trade</em>
  </h1>
</div>

    </div>
  </div>
  <section id="sub-hero">
    <div class="container">
      <div class="row">
  <div class="span4">
    <h2>about me</h2>
    <p>A Random Sys Admin by Trade, Hacker by Choice, Loves Linux, Puppet, Ruby, Monitoring, and a lot.</p>
  </div>
  <div class="span6">
    <h2>open source projects</h2>
    <dl class="dl-horizontal">
	    <dt><a href="https://github.com/deepakmdass88/">TweetGrabber</a><a href="https://github.com/deepakmdass88/" rel="tooltip" title="open sourced at Github"><img class="social_icon" title="Github" alt="github icon" src="/images/glyphicons_381_github.png"></a></dt>
	    <dd>A Live Tweet Grabber based built on Ruby+REDIS+SINATRA</dd>
      <dt><a href="https://github.com/deepakmdass88/ruby-virtmgr.git">Ruby-Virtmgr   </a><a href="https://github.com/deepakmdass88/ruby-virtmgr.git" rel="tooltip" title="open sourced at Github"><img class="social_icon" title="Github" alt="github icon" src="/images/glyphicons_381_github.png"></a></dt>
      <dd>A simple CLI Ruby app for Managing KVM based VM&#8217;s</dd>
    </dl>
  </div>
  <div class="span2">
    <h2>found on</h2>
    <a href="https://github.com/deepakmdass88/" rel="tooltip" title="Github"><img class="social_icon" title="Github" alt="github icon" src="/images/glyphicons_381_github.png"></a>
    <a href="http://www.linkedin.com/pub/deepak-dass/44/54/602" rel="tooltip" title="Linkedin"><img class="social_icon" title="Linkedin" alt="Linkedin icon" src="/images/glyphicons_377_linked_in.png"></a>
    <a href="http://twitter.com/deepakmdass88" rel="tooltip" title="Twitter"><img class="social_icon" title="Twitter" alt="Twitter icon" src="/images/glyphicons_391_twitter_t.png"></a>
    <a href="https://plus.google.com/105770729176086017609/posts" rel="tooltip" title="Google Plus"><img class="social_icon" title="Google Plus" alt="Google Plus icon" src="/images/glyphicons_386_google_plus.png"></a>
    <a href="http://www.quora.com/Deepak-M-Dass" rel="tooltip" title="Quora"><img class="social_icon" title="Quora" alt="Quora icon" src="/images/glyphicons_385_quora.png"></a>
    <h2>contact at</h2>
    <a href="mailto:deepakmdass88@gmail.com">deepakmdass88@gmail.com</a>
  </div>
</div>

    </div>
  </section>
  <div class="container">
    <div class="row">
    
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/23/sensu-cloud-monitoring-tool/">Sensu - Cloud Monitoring Tool</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-04-23T22:20:00+05:30" pubdate data-updated="true">Apr 23<span>rd</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/debian/'>Debian</a>, <a class='category' href='/blog/categories/monitoring/'>Monitoring</a>, <a class='category' href='/blog/categories/sensu/'>Sensu</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>Monitoring always plays an important role, especially for sysadmins. There are a lot of Monitoring tools available, like Nagios, Zenoss, Icinga etc. <code>Sensu</code> is a new generation Cloud monitoring tool designed by <a href="http://www.sonian.com/cloud-monitoring-sensu/">Sonian</a>. <em>Sensu</em> is bascially written in <strong><em>Ruby</em></strong>, uses <strong><em>RabbitMQ</em></strong> Server as the Message Broker for Message transactions, and <strong>Redis</strong> for storing the data&#8217;s.</p>

<p> Sensu has <strong>3</strong> operation Mode.</p>

<p> 1) <strong>Request-Reply Mode</strong>, where the server will send a check request to the clients through the RabbitMQ and the clients will reply back the results.</p>

<p> 2) <strong>Standalone Mode</strong>, where the server will not send any check request, instead the client itself will run the checks according to interval mentioned, and sends the results to the sensu master through the Result queue in RabbitMQ.</p>

<p> 3) <strong>Push Mode</strong>, where the client will send out results to a specific handler.</p>

<p>So now we can start installing the dependencies for sensu, ie, RabbitMQ and Redis.</p>

<h3>Setting up RabbitMQ</h3>

<p>Let&#8217;s add the <strong>RabbitMQ</strong> official APT repo.</p>

<pre><code>$ echo "deb http://www.rabbitmq.com/debian/ testing main" &gt;/etc/apt/sources.list.d/rabbitmq.list

$ curl -L -o ~/rabbitmq-signing-key-public.asc http://www.rabbitmq.com/rabbitmq-signing-key-public.asc

$ apt-key add ~/rabbitmq-signing-key-public.asc &amp;&amp; apt-get update
</code></pre>

<p>Now we can install RabbitMQ</p>

<pre><code>$ apt-get install rabbitmq-server erlang-nox
</code></pre>

<p>Now we need to generate SSL certificates for RabbitMQ and the sensu clients. We can use RabbitMQ with out ssl also, but it will more secure with SSL, <a href="http://github.com/joemiller">@joemiller</a> has wrote a script to generate the SSL certificates. It&#8217;s avaliable in his GitHub <a href="http://github.com/joemiller/joemiller.me-intro-to-sensu.git">repo</a>. Clone the repo and modify the &#8220;openssl.cnf&#8221; according to our need and then we can go ahead with generating the certificates.</p>

<pre><code>$ git clone git://github.com/joemiller/joemiller.me-intro-to-sensu.git

$ cd joemiller.me-intro-to-sensu/

$ ./ssl_certs.sh clean &amp;&amp; /ssl_certs.sh generate
</code></pre>

<p>Now copy the server key and cert files to the RabbitMQ folder in &#8220;/etc/rabbitmq/&#8221;</p>

<pre><code>$ mkdir /etc/rabbitmq/ssl

$ cp server_key.pem /etc/rabbitmq/ssl/

$ cp server_cert.pem /etc/rabbitmq/ssl/

$ cp testca/cacert.pem /etc/rabbitmq/ssl/
</code></pre>

<p>Now create the RabbitMQ config file, &#8220;/etc/rabbitmq/rabbitmq.config&#8221;, and add the following lines in it.</p>

<pre><code>[
  {rabbit, [
      {ssl_listeners, [5671]},
      {ssl_options, [{cacertfile,"/etc/rabbitmq/ssl/cacert.pem"},
               {certfile,"/etc/rabbitmq/ssl/server_cert.pem"},
               {keyfile,"/etc/rabbitmq/ssl/server_key.pem"},
               {verify,verify_peer},
               {fail_if_no_peer_cert,true}]}
    ]}
].
</code></pre>

<p>Once the config file is created, restart the RabbitmQ server. Now RabbitMQ has a cool management console, we can enable this by running &#8221;<strong><em>rabbitmq-plugins enable rabbitmq_management</em></strong>&#8221; in console. Once the Management console is enabled, we can access it RabbitMQ Web UI: <strong>Username is &#8220;guest&#8221;, password is &#8220;guest&#8221; - http://SENSU-SERVER:55672</strong>. Protocol amqp should be bound to port 5672 and amqp/ssl on port 5671.</p>

<p>Now let&#8217;s create a vhost and user for Sensu in RabbitMQ.</p>

<pre><code> $ rabbitmqctl add_vhost /sensu

 $ rabbitmqctl add_user sensu mypass

 $ rabbitmqctl set_permissions -p /sensu sensu ".*" ".*" ".*"
</code></pre>

<h3>Setting up Redis Server</h3>

<p>Now we can set up Redis server. This will used by Sensu for stroring data&#8217;s. Ubuntu&#8217;s Apt repo ships with latest Redis server, so we can directly install it.</p>

<pre><code>$ apt-get install redis-server
</code></pre>

<h3>Installing Sensu Server</h3>

<p>Sensu has a public repository which can be used to install the necessary sensu packages. First we need to add the repository public key.</p>

<pre><code>$ wget -q http://repos.sensuapp.org/apt/pubkey.gpg -O- | sudo apt-key add -
</code></pre>

<p>Now add the repo sources in APT</p>

<pre><code>$ echo " deb     http://repos.sensuapp.org/apt sensu main" &gt;&gt; /etc/apt/sources.list &amp;&amp; apt-get update

$ apt-get install sensu
</code></pre>

<p>Enable the sensu services to start automatically during system startup.</p>

<pre><code>$ update-rc.d sensu-server defaults

$ update-rc.d sensu-api defaults

$ update-rc.d sensu-client defaults

$ update-rc.d sensu-dashboard defaults
</code></pre>

<p>Copy the client ssl cert and key to <strong>/etc/sensu</strong> folder, say to a subfolder ssl.</p>

<pre><code>$ cp client_key.pem client_cert.pem  /etc/sensu/ssl/
</code></pre>

<p>Now we need setup the sensu master, create a file &#8221;<strong>/etc/sensu/config.json</strong>&#8221; and add the below lines.</p>

<pre><code>         {
        "rabbitmq": {
          "ssl": {
            "private_key_file": "/etc/sensu/ssl/client_key.pem",
            "cert_chain_file": "/etc/sensu/ssl/client_cert.pem"
          },
          "port": 5671,
          "host": "localhost",
          "user": "sensu",
          "password": "mypass",
          "vhost": "/sensu"
        },
        "redis": {
          "host": "localhost",
          "port": 6379
        },
        "api": {
          "host": "localhost",
          "port": 4567
        },
        "dashboard": {
          "host": "localhost",
          "port": 8080,
          "user": "admin",
          "password": "sensu@123"
        },
        "handlers": {
          "default": {
            "type": "pipe",
            "command": "true"
          }
        }
      }
</code></pre>

<p>By default sensu package comes with all sensu-server,sensu-client,sensu-api and sensu-dashboard., If we dont want to use the current machine as a client, we can stop the sensu-client from running, and do not create the client config. But for testing purpose, i&#8217;m going to add the current machine as client also. Create a file &#8221;<strong>/etc/sensu/conf.d/client.json</strong>&#8221; and add the client configuration in JSON format.</p>

<pre><code>        {
          "client": {
          "name": "sensu.test.com",
          "address": "192.168.1.108",
          "subscriptions": [ "vmmaster" ]
         }
       }
</code></pre>

<p>Now restart the sensu-client to affect the changes. The logs are recorded at &#8221;<strong>/var/log/sensu/sensu-client.log</strong>&#8221; file. We can access the sensu-dashboard from &#8220;http://SENSU SERVER:8080&#8221;, with the username and password mentioned in the config.json file.</p>

<h3>Setting up a Separate Sensu-Client Node</h3>

<p>If we want to setup sensu-client on a separate node, just dd the Sensu apt repo, and install the sensu package. After that just enable only the sensu-client service and remove all other sesnu-services. Then create a config.json file and add only the rabbitmq server details in it. Now generate a separate SSL certificate for the new client and use that in the config file.</p>

<pre><code>       {
      "rabbitmq": {
        "ssl": {
          "private_key_file": "/etc/sensu/ssl/client1_key.pem",
          "cert_chain_file": "/etc/sensu/ssl/client1_cert.pem"
        },
        "port": 5671,
        "host": "192.168.1.108",
        "user": "sensu",
        "password": "mypass",
        "vhost": "/sensu"
      }
    }
</code></pre>

<p>Now create the  &#8220;client.json&#8221; in the &#8220;/etc/sensu/conf.d/&#8221; folder.</p>

<pre><code>        {
              "client": {
              "name": "client1.test.com",
              "address": "192.168.1.212",
              "subscriptions": [ "vmmaster" ]
             }
           }
</code></pre>

<p>Restart the the sensu-clinet, and check the &#8220;/var/log/sensu/sensu-client.log&#8221;, if things goes fine, we can see client connecting to the RabbitMQ server also we can see the config is getting applied.</p>

<pre><code>{"timestamp":"2013-04-23T22:53:27.870728+0530","level":"warn","message":"config file applied changes","config_file":"/etc/sensu/conf.d/client.json","changes":{"client":[null,{"name":"client1.test.        com","address":"192.168.1.212","subscriptions":["vmmaster"]}]}}
{"timestamp":"2013-04-23T22:53:27.879671+0530","level":"info","message":"loaded extension","type":"mutator","name":"only_check_output","description":"returns check output"}
{"timestamp":"2013-04-23T22:53:27.883504+0530","level":"info","message":"loaded extension","type":"handler","name":"debug","description":"outputs json event data"}
</code></pre>

<p>Once the Sensu Server and Client are configured successfully, then we can go ahead adding the check&#8217;s. One of the best thing of sensu, all the config&#8217;s are written in JSON format, which very easy for us to create as well as to understand things. In the next blog, i will explain on how to create the check&#8217;s and how to add these check&#8217;s to various clients, and how to add handler&#8217;s like Email alerts, Sending Metrics to graphite.</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/14/haraka-a-nodejs-based-smtp-server/">HARAKA - a NodeJS Based SMTP Server</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-04-14T22:51:00+05:30" pubdate data-updated="true">Apr 14<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/debian/'>Debian</a>, <a class='category' href='/blog/categories/mailserver/'>MailServer</a>, <a class='category' href='/blog/categories/nodejs/'>Nodejs</a>, <a class='category' href='/blog/categories/smtp/'>SMTP</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>Today i came across a very interesting project in GITHUB. <a href="https://github.com/baudehlo/Haraka.git">HARAKA</a> is an SMTP server written completely in <em>NodeJS</em>. Like the qpsmtpd, apart from the core SMTP features we can improve the functionality using small plugins. There are very good pluginsi for HARAKA, basically in javascripts. Like Postfix,Qmail, we can easily implements all sorts of checks and features with the help of these plugins.</p>

<p>Setting up <code>HARAKA</code> is very simple. In my setup, i will be using HARAKA as my primary smtp server, where i will implement all my filterings and then i will relay to a qmail server for local delivery. There is plugin written by <a href="https://github.com/madeingnecca/haraka-plugins.git">@madeingnecca</a> in github, for directly delivering the mails to user&#8217;s INBOX (mail box should be in <em>MAILDIR</em> format). In the real server&#8217;s we use LDAP backend for storing all the USER databases. So before putting HARAKA into production, i need a to rebuild the auth plugin so that HARAKA can talk to LDAP for user authentication in SMTP.</p>

<p>So first we need to install <strong>NodeJS</strong> and <strong>NPM (Node Package Manager)</strong>. There are several ways for installing NodeJS. We can compile it from the source, or we can use <strong><em>NVM (Node Version Manager)</em></strong>, or we can install the packages from APT in Debian machines. But i prefer source code, because official APT repo has older versions of NodeJS, which will create compatibility issue. Current version is <em>&#8220;v0.10.4&#8221;</em>. Building NodeJS from source is pretty simple.</p>

<p>Just Download the latest source code from <strong>&#8220;http://nodejs.org/download/&#8221;</strong></p>

<pre><code>$ wget http://nodejs.org/dist/v0.10.4/node-v0.10.4.tar.gz

$ tar xvzf node-v0.10.4.tar.gz &amp;&amp; cd node-v0.10.4

$  ./compile 

$ make &amp;&amp; make install
</code></pre>

<p>Once NodeJS is installed, we can go ahead with <code>HARAKA</code>.</p>

<pre><code>$ git clone https://github.com/baudehlo/Haraka.git
</code></pre>

<p>Now go inside to the <em>Haraka</em> folder and run the below command. All the dependency packages are mentioned in the <strong>package.json</strong> file.</p>

<pre><code>$ npm install
</code></pre>

<p>The above command will install all the necessary modules mentioned in the package.json file and will setup HARAKA. Now we can setup a separate service folder for HARAKA.</p>

<pre><code>$ haraka -i /etc/heraka     
</code></pre>

<p> The above  command will create the heraka folder in <strong>/etc/</strong> and it will create  creates config and plugin directories in there, and automatically sets the host name used by Haraka to the output of the hostname command. Now we need to setup up the <em>port number</em> and <em>ip</em> which HARAKA SMTP service should listen. Go to config folder in the newly created haraka service folder and open the <strong>&#8220;smtp.ini&#8221;</strong> file, and mention the port number and ip.</p>

<p>Now before starting the smtp service, first let&#8217;s disable all the plugins, so that we can go in steps. In the config folder, open the <em>&#8220;plugin&#8221;</em> file, and comment out all the plugins, because by default haraka will not create any plugin scripts, so most of them mentioned in that will not work. So we will start using the plugins, once we have copied the corresponding plugin&#8217;s js files to the plugin directory inside our service directory.</p>

<p>Let&#8217;s try running the <code>HARAKA</code> foreground and see if it starts and listens on the port we mentioned.</p>

<pre><code>$ haraka -c /etc/haraka
</code></pre>

<p>Once <code>HARAKA</code> SMTP service starts, we can see the line &#8221;<strong>[NOTICE] [-] [core] Listening on :::25</strong>&#8221; in the STDOUT, which means HARAKA is listening on port 25. We can just Telnet to port 25 and see if we are getting SMTP banner.</p>

<p>Now we can try out a plugin. Heraka has a <em>spamassassin</em> plugin. So will try it out. So first install spamassassin and start the spam filtering.</p>

<pre><code>$ apt-get install spamassassin spamc
</code></pre>

<p>Now from the plugin folder inside the git source folder of HARAKA, copy the <strong>spamassassin.js</strong> and copy it to the plugin folder of our service directory. By default plugin folder is not created inside the service directory, so create it. Now we need to enable the service. Inside the config folder of our service directory, create a config file <strong>&#8220;spamassassin.ini&#8221;</strong>, and inside the file fill in the necessary details like, <strong>&#8220;reject_thresold&#8221;, &#8220;subject_prefix&#8221;, &#8220;spamd_socket&#8221;</strong>. Now before starting the plugin, we need to add it in the plugin, inside the config folder. Once spamassassin plugin is added, we can start the HARAKA smtp service. If the plugin is added properly, then we can see the below lines in the stdout,</p>

<pre><code>[INFO] [-] [core] Loading plugin: spamassassin
[DEBUG] [-] [core] registered hook data_post to spamassassin.hook_data_post
</code></pre>

<p>Now using swaks, we can send a test mail see, if spam assassin is putting scores for the emails. Like this we can enable all other plugins, based on our needs.</p>

<p>Since i&#8217;m going to relay the mails, i need to make HARAKA to accept mails for all my domains. For that i need to define all my domains on HARAKA. In the config folder, open the file <strong>&#8220;host_list&#8221;</strong>, and add all the domains for which HARAKA should accept mails. There also a regular expression option available for, which can be done in <strong>&#8220;host_list_regex&#8221;</strong> file.</p>

<p>Now we need to add, smtp relay, for that edit the <em>&#8220;smtp_forward.ini&#8221;</em> file and mention the relay host ip, port number and auth details(if required). Now we can restart the <code>HARAKA</code> service and we can check SMTP relay by sending test mails using swaks.</p>

<p>I haven&#8217;t tried the Auth plugin yet, but soon i will be trying it. If possible, i will try to use LDAP backend for authentication, so that HARAKA can be used a full fledged SMTP service. More developments are happening in this, hope it wil become a good competitor &#8230;</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/11/monitoring-with-zenoss/">Monitoring With ZENOSS</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-04-11T17:03:00+05:30" pubdate data-updated="true">Apr 11<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/centos/'>Centos</a>, <a class='category' href='/blog/categories/monitoring/'>Monitoring</a>, <a class='category' href='/blog/categories/zenoss/'>Zenoss</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>It&#8217;s being a year since i have really played with Centos or any Redhat based Distro&#8217;s. I saw a few videos on <a href="http://www.youtube.com/user/zenoss">youtube</a> realting to <strong>zenoss</strong>, which is a new generation monitoring tool. Later i attended two <strong><em>zenoss</em></strong> webinar&#8217;s, which made to try it out in own infrastructure. In this blog i will explain  how to setup zenoss on a Centos6.4 machine. Make sure that you have atleast 2GB of Ram. Initially i put 1GB of Ram and 2GB of swap in my Centos VM. But when i started the zenoss services, the whole and ram and swap was consumed and finaly i was not able to start the services.</p>

<p>Basicaly zenoss need <strong><em>RabbitMQ messaging server, JAVA6, MYSQL</em></strong> as its dependencies. There is an automated script available from the <a href="http://wiki.zenoss.org/Install_Zenoss">zenos website</a>, which will download and install all necessary dependencies. It&#8217;s a bash script. We can download it from the below link.</p>

<pre><code>$  wget --no-check-certificate https://github.com/zenoss/core-autodeploy/tarball/4.2.3 -O auto.tar.gz
</code></pre>

<p>Once we extract the above tar ball, we can see a bunch of files. <code>zenpack_actions.txt</code> file contains the list of zenpacks which is going to be installed. We can modify it based on our needs.</p>

<p>Once done, we can start the installer script.</p>

<pre><code>$ ./core-autodeploy.sh
</code></pre>

<p>This will start by downloading the zenoss rpm file. Once the installation completed, it was giving an error, saying that <em>&#8220;connection reset&#8221;</em> while installing the zenpacks. I was going through all the log files, finally i found that the error was in the rabbitmq. The zenoss user authentication was failing. Below is the error which iwas getting in the rabbitmq log.</p>

<pre><code>=INFO REPORT==== 10-Apr-2013::09:37:00 ===
accepting AMQP connection &lt;0.3533.0&gt; (127.0.0.1:38662 -&gt; 127.0.0.1:5672)

=ERROR REPORT==== 10-Apr-2013::09:37:03 ===
closing AMQP connection &lt;0.3533.0&gt; (127.0.0.1:38662 -&gt; 127.0.0.1:5672):
{channel0_error,starting,
            {amqp_error,access_refused,
                        "PLAIN login refused: user 'zenoss' - invalid credentials",
                        'connection.start_ok'}}
</code></pre>

<p>The error says that the zenoss user credential is wrong. So using <strong><em>&#8220;rabbitmqctl&#8221;</em></strong> command i reset the zenoss user password. Once the password is changed, we have to mention the new passowrd in the zenoss <code>global.conf</code> file. This file will be present in <strong><em>&#8220;/opt/zenoss/etc&#8221;</em></strong> location. Open the the <code>global.conf</code> file, and replace the <strong><em>amqppassword</em></strong> with the new password. By default during installation, the script generates a base64 encoded random password using the openssl. Once we hab=ve replaced the password, we can start the zenoss service.</p>

<pre><code>$ service zenoss start
</code></pre>

<p>Now while starting the service, zenoss will continue the installing the zenpacks. Once the service is started, we can access the WebGUI from <strong><em>&#8220;http://server_ip:8080&#8221;</em></strong> url. Initially it will ask us to set the password for the admin user as well as to create a secondary user. More over  it will ask us to add hosts to monitor, we can skip this step and move the dashboard. Later on we can add the hosts directly from the infrastructure tab. I&#8217;ve added my vps as well as few of my local server&#8217;s with snmp, so far it is working perfectly. There many cool stuffs inside zenoss, hope this will a cool playground &#8230;</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/07/setting-up-apache-cloudstack/">Setting Up Apache CloudStack</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-04-07T22:16:00+05:30" pubdate data-updated="true">Apr 7<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/cloud/'>Cloud</a>, <a class='category' href='/blog/categories/ubuntu-/'>Ubuntu,</a>, <a class='category' href='/blog/categories/virtualization-/'>Virtualization,</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>Today i was completely playing around with virtualization. I was playing around with Foreman and KVM, then i got <code>WebVirtmanager</code> to play around, which is working perfectly with LVM storage pool. It&#8217;s almost a week since i saw a few videos related to Apache Cloudstack, so today i decided to give it a try. In this blog i will explain on how to set up Apache CloudStack on an ubuntu 12.10 Machine. Apache Cloudstack is one of the coolest cloud platform&#8217;s available. It supports hypervisors like KVM, XEN, vSphere. The latest version is 4.0.1-incubating. The source can be downloaded from <a href="http://apache.techartifact.com/mirror/incubator/cloudstack/releases/4.0.1-incubating/apache-cloudstack-4.0.1-incubating-src.tar.bz2">here</a>. There is a very good documentation available from <a href="http://cloudstack.apache.org/docs/en-US/Apache_CloudStack/4.0.1-incubating/pdf/Installation_Guide/Apache_CloudStack-4.0.1-incubating-Installation_Guide-en-US.pdf">Cloudstack</a>.</p>

<h3>Building Debian Packages from the Source</h3>

<p>First we need to install the below dependency packages.</p>

<pre><code>1.  Apache Ant
2.  JDepend
3.  Apache Maven (version 3)
4.  Java (Java 6/OpenJDK 1.6)
5.  Apache Web Services Common Utilities (ws-commons-util)
6.  MySQL
7.  MySQLdb (provides Python database API)
8.  Tomcat 6 (not 6.0.35)
9.  genisoimage
10. dpkg-dev and their dependencies
</code></pre>

<p>Maven 3, which is not currently available in 12.10. So, we&#8217;ll need to add a PPA repository that includes Maven 3</p>

<pre><code>$ add-apt-repository ppa:natecarlson/maven3
</code></pre>

<p>The current ppa supports only ubuntu 12.04 aka Precise, so edit <code>/etc/apt/sources.list.d/natecarlson-maven3-quantal.list</code> and replace &#8220;quantal&#8221; with &#8220;precise&#8221;. So now the content of the file looks like below one</p>

<pre><code>deb http://ppa.launchpad.net/natecarlson/maven3/ubuntu precise main
deb-src http://ppa.launchpad.net/natecarlson/maven3/ubuntu precise main
</code></pre>

<p>Now we can start installing the dependencies,</p>

<pre><code>$ apt-get install ant debhelper openjdk-6-jdk tomcat6 libws-commons-util-java genisoimage python-mysqldb libcommons-codec-java libcommons-httpclient-java liblog4j1.2-java python-software-properties maven3
</code></pre>

<p>Now we can resolve the buildtime depdencies for CloudStack by running the below command.</p>

<pre><code>$ mvn3 -P deps.
</code></pre>

<p>Now there is a small <a href="https://issues.apache.org/jira/browse/CLOUDSTACK-1589">bug</a>, which add the dependency of &#8220;chkconfig&#8221; package to a few of the cloudstack packages. But &#8220;chkconfig&#8221; is required for Redhat based machines, not for debian based machines. So edit &#8220;Debian/control&#8221; file inside the apache cloudstack source folder and remove &#8220;chkconfig&#8221; from the dependency list. After that we can start building the debian packages.</p>

<pre><code>$ dpkg-buildpackage -uc -us
</code></pre>

<p>The above command will build 16 debian packages.</p>

<h3>Setting up a Local APT repo</h3>

<p>Now we can set up a local apt repo so that we can install all these 16 packages along with their corresponding dependencies. First ensure that &#8220;dpkg-dev&#8221; is installed. After that copy all the packages to a specific location in order to create the local repo.</p>

<pre><code>$ mkdir -p /var/www/cloudstack/repo/binary
$ cp *.deb /var/www/cloudstack/repo/binary
$ cd /var/www/cloudstack/repo/binary
$ dpkg-scanpackages . /dev/null | tee Packages | gzip -9 &gt; Packages.gz
</code></pre>

<p>We need to configure the local machine to use this local repo. Add the local repository in <code>echo "deb http://server_url/cloudstack/repo/binary ./" &gt; /etc/apt/sources.list.d/cloudstack.list</code> and run &#8220;apt-get update&#8221;. Now we can install the cloudstack packages.</p>

<pre><code>$ apt-get install cloud-agent cloud-agent-deps cloud-agent-libs cloud-awsapi cloud-cli cloud-client cloud-client-ui cloud-core cloud-deps cloud-python cloud-scripts cloud-server cloud-setup cloud-system-iso cloud-usage cloud-utils
</code></pre>

<p>Now from the web browser go to &#8220;http://server_url:8080/client/. The default Username is &#8220;admin&#8221; and password is &#8220;password&#8221;. For the admin user, we don&#8217;t need to provide the domain option.</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/07/webvirtmanager-and-libvirt-kvm/">WebVirtManager and Libvirt-KVM</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-04-07T13:49:00+05:30" pubdate data-updated="true">Apr 7<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/libvirt/'>Libvirt</a>, <a class='category' href='/blog/categories/ubuntu-/'>Ubuntu,</a>, <a class='category' href='/blog/categories/virtualization-/'>Virtualization,</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>It&#8217;s been almost two years since i&#8217;ve started using <em>KVM</em> and <em>Libvirt</em> for creating Virtual machines. All our production server&#8217;s are VM&#8217;s, so far KVM has never let us down. The <code>Virt Manager</code> is a wonderful tool taht can installed in most of the linux distributions. But when i switched to ma new MacAir, i could not find a similar tool, so i decided to use a web based tool, so that it can be used from anywhere irrespective of devices. I came across this <a href="https://www.webvirtmgr.net/">WebVirtManager</a>, a python and django based web app, which is very active in development, so i decided to give it a try. In my libvirt setup, i&#8217;m using LVM as my storage pooli for my VM&#8217;s, so the main thing which i wanted to check was, whether the <code>WebVirtManager</code> is able to create LVM&#8217;s, so that it can be used as the <strong><em>HDD image</em></strong> for my new VM&#8217;s from the WebInterface.</p>

<p>First, we need to install the basic dependency packages.</p>

<pre><code>$ apt-get install git python-django virtinst apache2 libapache2-mod-python libapache2-mod-wsgi
</code></pre>

<p>Now go to <code>libvirtd.conf</code>, and ensure that <em>&#8220;listen_tcp&#8221;</em> is enabled. Also go to <strong><em>&#8220;/etc/default/libvirt&#8221;</em></strong> and add the <strong><em>&#8220;-l&#8221;</em></strong> to the <strong><em>&#8220;libvirtd_opts&#8221;</em></strong>, so that libvirt will listen on tcp. The default port is &#8220;16509&#8221;.</p>

<p>Now we can clone the repository from the Github.</p>

<pre><code>$ git clone git://github.com/retspen/webvirtmgr.git
$ cd webvirtmgr
$ ./manage.py syncdb
</code></pre>

<p>While running the sync, it will ask to create a super user, so create the user, this user can be used to login to the <code>WebVirtManager</code> GUI. Now We can create a <em>virtualhost</em> in apache, and we can start the server. The Apache configurations are available in the Readme. I&#8217;ve added the below WSGI settings in my default apache sites.</p>

<pre><code>WSGIScriptAlias / /var/www/webvirtmgr/wsgi/django.wsgi
Alias /static /var/www/webvirtmgr/ virtmgr/static/
&lt;Directory /var/www/webvirtmgr/wsgi&gt;
 Order allow,deny
Allow from all
&lt;/Directory&gt;
</code></pre>

<p>Ensure that the directory is <strong><em>writable by apache user</em></strong>. But for testing, we can start the server from command line using the below command.</p>

<pre><code>$ ./manage.py runserver x.x.x.x:8000 (x.x.x.x - your IP address server)
</code></pre>

<p>So this command will start the <code>WebvirtManager</code>, which is listening at port &#8220;8000&#8221;. So from the Browser, we can access the url. The default usernmae and password is the one which we created during the syndb.  Now before adding the connection, we need to create a user which can access the libvirt. For that we are going to use <em>&#8220;saslpasswd2&#8221;</em>. Ensure that the package <em>sasl2-bin</em> is installed in the machine.</p>

<pre><code>$ saslpasswd2 -a libvirt testuser     # replace testuser is the user name.
</code></pre>

<p>To list all the user&#8217;s, we can use the <code>sasldblistusers2</code> command.</p>

<pre><code>$ sasldblistusers2 -f /etc/libvirt/passwd.db
$ testuser@cloud: userPassword        # Note that the actual user name is testuser@cloud, where cloud is the hostname of my server. This full user name has to be used for adding connections.
</code></pre>

<p>Now login to the <code>WebvirManager</code>, and click on <strong><em>&#8220;Add Connection&#8221;</em></strong>. Fill in the connection name, ip of the server, the user which we created using <em>saslpasswd2</em>, ie <strong><em>testuser@cloud</em></strong> and the password for that user.If everything goes fine, we can see the host connected. Now click on the &#8220;Overview&#8221;, to see the settings of the host.</p>

<p>Now i need to check the storage pool part. Since the storage pool is already active and running, it will get displayed at the storage pool option. If a new pool has to created, click at the <em>&#8220;add pool&#8221;</em> option, and select the &#8220;lvm&#8221; option, define the <strong><em>VolumeGroup</em></strong> name and the <strong><em>physical volumes</em></strong>.</p>

<p>I tried creating a new VM from the interface, while creating, i selected my VolumeGroup as the storage, and it sucessfully created an LVM with the specified size, and i able to continue my installtion using the vnc option avalable at the WebVirtManager.</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/03/19/virtualiation-using-linux-containers/">Virtualization Using Linux Containers</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-03-19T23:18:00+05:30" pubdate data-updated="true">Mar 19<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/debian/'>debian</a>, <a class='category' href='/blog/categories/linux/'>linux</a>, <a class='category' href='/blog/categories/virtualization/'>virtualization</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>LXC</strong> or <strong>Linux Continers</strong> is is an operating system-level virtualization, using which we can run multiple isolated Linux systems on a single host.  LXC relies on the <a href="http://en.wikipedia.org/wiki/Cgroups">cgroups</a> functionality of the Linux Kernels. <em>Cgroups (control groups)</em> is a Linux kernel feature to limit, account and isolate resource usage (CPU, memory, disk I/O, etc.) of process groups. LXC does not provide a virtual machine, but rather provides a virtual environment that has its own process and network space. It is similar to a chroot, but offers much more isolation.</p>

<p>First, let&#8217;s install the necessary packages.</p>

<pre><code>$ apt-get install lxc btrutils
</code></pre>

<p>By default in Ubuntu, when we install the lxc package, it will create a default bridge network called &#8220;lxcbr0&#8221;. If we don&#8217;t want to use this bridge network, we can disbale it by editing the <code>/etc/default/lxc</code> file. We can also create bridge networks using the <strong><em>&#8220;btrcl&#8221;</em></strong> or we can directly define the bridge networks in the interfaces file. There are a few templates, which gts shipped with the lxc package, which will be present in the <code>/usr/share/lxc/template</code>. I&#8217;m going to use the default template to create the containers. We can also use OPENVZ templates to create containers.</p>

<p>I&#8217;m going to keep my keep all my container&#8217;s files in a default path say &#8220;/lxc&#8221;</p>

<pre><code>$ mkdir /lxc
</code></pre>

<p>Now we can create the first debian container.</p>

<pre><code>$ mkdir /lxc/vm0    # where vm0 is the name of my conatiner.

$ /usr/share/lxc/templates/lxc-debian -p /lxc/vm0
</code></pre>

<p>Now this will install and build the necessary files for the container. If we go inside the vm0 folder, we can see two things, one is the config file, and second is the root folder of the container. This root folder will be the virtual environment for our container. Now we can edit the config file, to mention the default Network options.</p>

<pre><code>lxc.network.ipv4 = 192.168.0.123/24 # IP address should end with CIDR
lxc.network.hwaddr = 4a:59:43:49:79:bf # MAC address
lxc.network.link = br0 # name of the bridge interface
lxc.network.type = veth 
lxc.network.veth.pair = veth_vm0
</code></pre>

<p>Now we need to add the ip to the lxc&#8217;s interface file alos, for that we need to edit the <code>/lxc/vm0/rootfs/etc/network/interfaces</code> file and set the ip address in it for the interface <em>eth0</em>
We can create a bridge interface and we can bind it with the physical interface of the host, so that the lxc will be in the same network as that of the host. If there is a virtual network already existing, for example, when we install libvirt, it will create a bridge interface called &#8220;virbr0&#8221;, or in Ubuntu the lxc package installation wil create a bridge interface called &#8216;lxcbr0&#8217;, we can alos use those with lxc. Or we can define a bridge interface in the &#8220;interfaces&#8221; file. Below is a configuration of creating a bridge interface.</p>

<pre><code>    auto eth0
    iface eth0 inet manual

# Bridge setup
    iface br0 inet static
        bridge_ports eth0 
        address 192.168.0.2
        broadcast 192.168.0.255
        netmask 255.255.255.0
        gateway 192.168.0.1
</code></pre>

<p>If a separate network has to be given for the lxc&#8217;s, then we can to go for NATing. The below configuration on the interfaces file is for the NAT enabled.</p>

<pre><code>auto br0
iface br0 inet static
address 172.16.0.1
netmask 255.255.255.0
bridge_stp off
bridge_maxwait 5
pre-up  /usr/sbin/brctl addbr br0
post-up /usr/sbin/brctl setfd br0 0
post-up /sbin/iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
post-up echo 1 &gt; /proc/sys/net/ipv4/ip_forward
</code></pre>

<p>Once we are ready with the configurations, we can start our container using the below command.</p>

<pre><code>$ lxc-start -n vm0 -f /lxc/vm0/config
</code></pre>

<p>In the NAT scenario, the lxc machines are under the &#8220;172.16&#8221; network, while the host lies in &#8220;192.168.0&#8221; network. There are some good projects which works around with lxc, <a href="https://github.com/chrisroberts/vagabond">vagabond</a> is an example for that.Vagabond is a tool integrated with Chef to build local nodes easily and most importantly, quickly. Vagabond is built for Chef.</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/03/07/using-foreman-with-puppet-and-libvirt/">Using Foreman With Puppet and Libvirt</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-03-07T09:39:00+05:30" pubdate data-updated="true">Mar 7<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/foreman/'>Foreman</a>, <a class='category' href='/blog/categories/debian/'>debian</a>, <a class='category' href='/blog/categories/puppet/'>puppet</a>, <a class='category' href='/blog/categories/virtualization/'>virtualization</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p><em>TheForeman</em> is one of the best provisioning tools available. It&#8217;s purely open-sourced. And it natively supports <strong><em>puppet</em></strong> for provisioning the nodes. Foreman can talk to <strong>libvirt</strong> also, which makes us easy to create a VM and provision it on the way. In this blog i will be explaining on how to install Foreman from the source, how to integrate it with puppet to receive the logs and facts and make Foreman to use Libvirt for building VM&#8217;s.</p>

<h3>Setting up Foreman</h3>


<p>First will install the basic depenencies. Since i&#8217;m using the git repository of Foreman for installation, git package has to be installed. Moreover we also need a database for Foreman. I&#8217;m going to use Mysql for that.</p>

<pre><code>$ apt-get install git mysql-server ruby-mysql libmysql-ruby1.9.1 libmysqlclient-dev libvirt-dev 
</code></pre>

<p>Now clone the repository from github. The newer build&#8217;s works with <em>Puppet 3.0</em>.</p>

<pre><code>$ git clone https://github.com/theforeman/foreman.git -b develop
</code></pre>

<p>Ensure that &#8221;<strong><em>ruby</em></strong> and <strong><em>bundler</em></strong>&#8221; is installed in the machine.</p>

<pre><code>$ bundle install --without postgresql sqlite
</code></pre>

<p>Now we can start configuring Foreman. Copy the sample config files.</p>

<pre><code>$ cp config/settings.yaml.example config/settings.yaml
$ cp config/database.yml.example config/database.yml
</code></pre>

<p>Now create a database for FOreman and add the database details in the <code>database.yml</code>. Now add the puppet master details in the <code>settings.yaml</code>. Since i&#8217;m going to use the Foreman in production mode, i&#8217;ve commented out the Development and test environment setting in <code>database.yml</code>. Once the config files are set, we can now go ahead with db migration.</p>

<pre><code>$ RAILS_ENV=production bundle exec rake db:migrate
</code></pre>

<p>Now we can check whether the server is fine or not by using the following command. The below command will start the Foreman with the builtin web server, and we can access the webui from <code>http://foreman_ip:3000</code> in the browser. By default there is no authentication set for the WebUI. But LDAP Authentication can be set for the WebUI. Details are availabe in the foreman&#8217;s <a href="http://theforeman.org/manuals/1.1/index.html#4.1WebInterface">documentation</a>.</p>

<pre><code>$ RAILS_ENV=production rails server
</code></pre>

<p>Once the Foreman server is working fine, we can configure puppet to send its logs and facts to foreman. In the puppet clients, add <code>report = true</code> in the puppet.conf file. Now in the puppet master, we need to do a few stuffs.</p>

<p>Copy this foreman <a href="https://raw.github.com/theforeman/puppet-foreman/master/templates/foreman-report.rb.erb">report</a> file to puppet&#8217;s report library.</p>

<p>In my case it is <code>/usr/lib/ruby/vendor_ruby/puppet/reports/</code> and rename it to foreman.rb. Now add <code>reports=log, foreman</code> in the <strong><em>puppet.conf</em></strong> file. Also add the foreman url in the foreman.rb file.</p>

<pre><code>foreman_url='http://foreman:3000    # or use ip instead of foreman, if DNS/Host entry is not there for Foreman
</code></pre>

<p>Now for sending facts to puppet, we can put a cron job to execute the below command</p>

<pre><code>$ rake puppet:import:hosts_and_facts RAILS_ENV=production
</code></pre>

<p>Now once the puppet clients starts running, they will send the logs to Foreman, and can be viewed in the WebUI.</p>

<h3>Foreman and Libvirt</h3>


<p>Now in the same machine i&#8217;ve installed libvirt and libvirt-ruby. Now create a user &#8220;foreman&#8221; and generate ssh-key for the user. Now copy the public key to the &#8220;authorized_keys&#8221; file of the root user. This is actually needed if your libvirt host is different.</p>

<p>Now go to the Foreman WebUI, Go to  <strong><em>More</em></strong> &#8212;&#8211;> <strong><em>provisioning</em></strong> &#8212;&#8211;> <strong><em>Compute Resources</em></strong>. Now click on &#8220;New Compute Resource&#8221;, Add a name for the Resource, Select the provider as <em>Libvirt</em>, and URL is <code>qemu:///system</code>, since libvirt and foreman resides on the same system. We can also test the connection to libvirt. IF the parameters we entered are fine, Foreman can talk to libvirt directly.</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/02/26/using-snmp-with-icinga/">Using SNMP With Icinga</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-02-26T21:55:00+05:30" pubdate data-updated="true">Feb 26<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/debian/'>debian</a>, <a class='category' href='/blog/categories/icinga/'>icinga</a>, <a class='category' href='/blog/categories/monitoring/'>monitoring</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>In my previous i explained how to set up the Icinga monitoring system on Debian based machine. In this i will be explaining on how to use SNMP with icinga. Using SNMP we can get various info from a remote machine which can be used to icinga.</p>

<p>On the remote server we need to install the snmp server. In ordr to check whether the snmp is working fine, we can install the snmp client also on the same machine.</p>

<pre><code>apt-get install snmp snmp-server
</code></pre>

<p>From Debian Wheezy onwards, the <strong><em>snmp-mibs</em></strong> package has been removed from the debian repositories. But we can download the debian file from the squeeze repo. Since it has only a few depenencies and they can be installed from the debian repositories, we can manually install the mibs package. But in Ubuntu mibs package is still available in their repositories.</p>

<p>Once the package is installed we can run the <strong><em>download-mibs</em></strong> to install all the necessary mibs. Now once the snmpd package is installed, we need to comment the MIBS option in the <code>/etc/snmp/snmp.conf</code>. And define the basic settings like, location, contact etc in the <code>snmpd.conf</code> file. We can define the ip to which snmp should listen either in the snmpd.conf file or in the <code>/etc/default/snmp</code> file as an extra option. Once the settings are modified, we can start the snmpd service.</p>

<p> So now the service will listening on the port <em>631</em> on the ip which we defined, by default <strong>127.0.0.1</strong>. We can also enable authentication for snmp service, so that the snmp clients which passes the authentication will be able to get the result from the snmp service.</p>

<p>Once the snmp service has started on the remote server, we can test the snmp onnectivity from our icinga server using the nagios&#8217; <code>check_snmp plugin</code>. Once we are able to get results from the snmp service, we can deploy tese snmp services into our icinga host configurations to get the results from the remote server&#8217;s using the <strong><em>check_snmp command</em></strong>.</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/02/25/monitoring-servers-using-icinga/">Monitoring Server&#8217;s Using Icinga</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-02-25T21:44:00+05:30" pubdate data-updated="true">Feb 25<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/debian/'>debian</a>, <a class='category' href='/blog/categories/icinga/'>icinga</a>, <a class='category' href='/blog/categories/monitoring/'>monitoring</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>Last week we had severe outage in our US vps. The <em>load</em> was getting too high in the server, since it&#8217;s a hosting server, and so many of our clients are hosting their DNS, website and mail server in it. So i decided to implement a monitoring system. And i decided it to extend it to all of our client server&#8217;s so that we can have a fully fledged monitoring system in our company. I&#8217;m a great fan of Sensu and i play with it regularly, but this time i decided to setup <a href="http://icinga.org">Icinga</a> monitoring system, which can be used any System admin very easily. In this post i will be explaining on how to setup the <strong><em>icinga</em></strong> with it&#8217;s newest web interface called icinga-web. This setup works perfectly in <em>Debian</em> based OS. In my next post, i will be explaining on how to setup <em>SNMP</em> to work with icinga.</p>

<p>By default Ubuntu and Debian repositories has icinga packages.</p>

<pre><code>$ apt-get install icinga icinga-cgi icinga-common icinga-core icinga-idoutils icinga-web icinga-web-pnp mysql-server
</code></pre>

<p>Once the installation is completed, by default icinga has already created a config file for the local host, which can be found in <code>/etc/icinga/objects/</code>. Now we can access the default icinga web interface with <code>http://yoursystemip/icinga</code>. The default user will be <strong><em>icingaadmin</em></strong> and password will be the default password which we have setup during the installation. Now we can create the config files for other hosts and we should restart the icinga service. This will add the host&#8217;s to our default web interface. All the check commands are defined in the <code>/etc/nagios-plugins/config/</code> folder.</p>

<p>Now we need to set a contact so that icinga can send alerts to the specified email id. In the <code>/etc/icinga/objects/</code> there is a file called <strong><em>contacts_icinga.cfg</em></strong>, where we have to define the contact info.</p>

<pre><code>define contact{
    contact_name                    your_contact_name
    alias                           alias
    service_notification_period     24x7
    host_notification_period        24x7
    service_notification_options    w,u,c,r
    host_notification_options       d,r
    service_notification_commands   notify-service-by-email
    host_notification_commands      notify-host-by-email
    email                           your_contact_email_id
    }
</code></pre>

<p> The <strong><em>notify-service-by-email</em></strong> and <strong><em>notify-host-by-email</em></strong> commands are defined in the <code>/etc/icinga/commands.cfg</code> file. We can make changes to the format of the email alert by modifying this file. the &#8220;icinga-web&#8221; package will setup the basic config for the new icinga-web interface. Before starting the new interface we need to check a few settings for the new interface. First is the Database for the new interface. Ensure that the DB icinga-web and a user called icinga-web is created in the mysql. Now we need ensure that the database settings are correctly mentioned in the icinga-web settings. The settings are available in <code>/etc/icinga-web/conf.d/</code>. Now ensure that the database,user, and password are correctly mentioned in the <code>databases.xml</code> file. Now we need to ensure that the broker modules are enabled in the icinga.cfg file. comment out the below line in the icinga.cfg file to enable the idmod to enable the idomod broker module.</p>

<pre><code>broker_module=/usr/lib/icinga/idomod.so config_file=/etc/icinga/idomod.cfg
</code></pre>

<p>Also increase the log level to debug in both icinga as well as idomod, which helps to identify error if any. Now restart the icing and idomod services. Now go to the new interface by going to the following url, <code>http://ip/icinga-web</code>. the default user name is &#8220;root&#8221; and the passwod will be the one which we have given during installation</p>
</div>
  
  


</div>

      </article>
    
    
      <article class="span4">
        <div class="article-format">

  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/01/26/building-mailserver-with-postfix/">Building Mailserver With Postfix</a></h1>
    
    
      <p class="meta">
        
  


  
    <span class="byline author vcard">by <a href="https://plus.google.com/deepakmdass88?rel=author"><span class="fn">Deepak M Das</span></a></span>
  

 - 
        








  


<time datetime="2013-01-26T14:28:00+05:30" pubdate data-updated="true">Jan 26<span>th</span>, 2013</time> - 
        

posted in
<span class="categories">
  
    <a class='category' href='/blog/categories/debian/'>Debian</a>, <a class='category' href='/blog/categories/dovecot/'>Dovecot</a>, <a class='category' href='/blog/categories/mailserver/'>Mailserver</a>
  
</span>


        
      </p>
    
  </header>


  <div class="entry-content"><p>It&#8217;s been a week since i started playing around with <code>Postfix</code>. Though we are qmail lovers, a few days back one of my friend asked me to help him to build a Mail server. But he wanted to use Postfix as the MTA. I decided to integrate <em>LDAP</em>  also, so that he can have a centralized user management. So in this blog i will be explaining on how to set up postfix to use LDAP for user lookup as well as using <strong><em>Dovecot SASL</em></strong> for SMTP auth and <strong><em>Dovecot&#8217;s lda</em></strong> for delivering the mails to the user&#8217;s Mailboxes. I&#8217;m using Debian 6.4 as the base os. I&#8217;ve also installed <em>SLAPD</em>, and i&#8217;ve a few test user&#8217;s in it. My LDAP setup has two OU&#8217;s, People and Groups respectively.</p>

<p>First we will setup <em>Dovecot</em>. The Debian Squeeze repository has Dovecot 1.2, so i will be installing those.</p>

<pre><code>$ apt-get install dovecot-common dovecot-pop3d dovecot-imapd
</code></pre>

<p>Once dovecot is installed, we need to enable dovecot&#8217;s LDA and the dovecot&#8217;s SASL auth. Modify the dovecot.conf file as below. Since i&#8217;m using a virtual user <strong><em>vmail</em></strong>, i need to define the <em>mail_uid and mail_gid</em> as the vmail&#8217;s corresponding uid and gid. Also <em>login_user</em> must be <strong><em>postfix</em></strong></p>

<p>In the <em>lda</em> section,</p>

<pre><code>protocol lda {
 postmaster_address = postmaster@&lt;domain_name&gt;
 mail_plugin_dir = /usr/lib/dovecot/modules/lda
 deliver_log_format = msgid=%m: %$
 sendmail_path = /usr/sbin/sendmail
 rejection_subject = Rejected: %s
 auth_socket_path = /var/run/dovecot/auth-master
 log_path = /var/log/dovecot-deliver.log
 info_log_path = /var/log/dovecot-deliver.log
}
</code></pre>

<p>In the <em>auth</em> section,</p>

<pre><code>auth default {
 mechanisms = plain

  passdb ldap {
        args = /etc/dovecot/dovecot-ldap.conf
  }

  userdb ldap {
        args = /etc/dovecot/dovecot-ldap.conf
  }

  socket listen {
         master {  
    path = /var/run/dovecot/auth-master
        mode = 0666
        # Default user/group is the one who started dovecot-auth (root)
        user = vmail
        group = vmail   
        }

     client {
        path = /var/spool/postfix/private/auth
        mode = 0660
        user = postfix
        group = postfix
        }
</code></pre>

<p>Below is the content of my <em>dovecot-ldap.conf</em></p>

<pre><code>hosts = localhost
dn =  &lt;ldap_bind_dn&gt;
dnpass = &lt;ldap_bind_pwd&gt;
sasl_bind = no
auth_bind = yes
ldap_version = 3
base = &lt;ldap_base_dn&gt;
auth_bind = yes
pass_attrs = uid=user
pass_filter = (&amp;(objectClass=posixAccount)(uid=%u))
user_attrs = homeDirectory=home,mailQuotaSize=quota=dirsize:storage
user_filter = (&amp;(objectClass=posixAccount)(|(mail=%u)(mailAlternateAddress=%u)(uid=%u)))
</code></pre>

<p>So now Dovecot is ready, we need to go ahead with Postfix installation. We need to install the below packages.</p>

<pre><code>$ apt-get install postfix postfix-ldap
</code></pre>

<p>Once the packages are installed, we need to configure the main config file of postfix ie, <strong>main.cf</strong>. Below is the my configuration,</p>

<pre><code>myhostname = vagratn-postifx-box
smtpd_banner = &lt;smtp_banner&gt;
biff = no
# TLS parameters
smtpd_tls_cert_file=/etc/ssl/certs/server.pem
smtpd_tls_key_file=/etc/ssl/private/server.key
smtpd_use_tls=yes
smtpd_tls_session_cache_database = btree:${data_directory}/smtpd_scache
smtp_tls_session_cache_database = btree:${data_directory}/smtp_scache
alias_maps = hash:/etc/aliases
alias_database = hash:/etc/aliases
myorigin = /etc/mailname
mydestination = localhost
relayhost =
mynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128
mailbox_size_limit = 0
recipient_delimiter = +
inet_interfaces = all
home_mailbox = Maildir/
virtual_mailbox_maps = ldap:/etc/postfix/ldap_virtual_users.cf          #This ldap lookup will return user's MAilbox as the result from LDAPv
virtual_alias_maps = ldap:/etc/postfix/ldap_virtual_mailalt.cf      #This ldap lookup will return uid from LDAP
$alias_maps = hash:/etc/aliases,ldap:/etc/postfix/ldap_virtual_mailalt.cf
local_recipient_maps = $alias_maps
smtpd_sender_login_maps = ldap:/etc/postfix/ldap_senders.cf     #This ldap lookup will return uid attribute from LDAP
smtpd_sasl_type = dovecot
smtpd_sasl_path = private/auth
smtpd_sasl_auth_enable = yes
mailbox_transport = dovecot
dovecot_destination_recipient_limit = 1
virtual_mailbox_domains = &lt;add virtual domains here&gt;
virtual_transport = dovecot
</code></pre>

<p>We can also mention the SMTP sender and recipient restrictions in the above file,</p>

<pre><code>smtpd_client_restrictions=
        permit_mynetworks,

smtpd_recipient_restrictions=
        permit_mynetworks,
        permit_sasl_authenticated,
        reject_unverified_recipient,
        reject_invalid_hostname,
        reject_non_fqdn_hostname,
        reject_non_fqdn_sender,
        reject_non_fqdn_recipient,
        reject_unknown_sender_domain,
        reject_unknown_recipient_domain,
        reject_unauth_pipelining,
        permit_auth_destination,
        reject_unauth_destination,

smtpd_sender_restrictions=
        reject_unknown_sender_domain,
        reject_unlisted_sender,
        reject_authenticated_sender_login_mismatch,
</code></pre>

<p>Below are the contents of the various LDAP lookup file&#8217;s contents. We can verify this lookup&#8217;s using postmap command. &#8221;<strong><em>postmap -q <query> ldap:/<lookupfile></em></strong>&#8221;</p>

<pre><code>########ldap_virtual_mailalt.cf########

    server_host = ldap://localhost
    version = 3
    search_base = &lt;ldap_base_dn&gt;
    bind_dn = &lt;ldap_bind_dn&gt;
    bind_pw = &lt;ldap_bind_password&gt;
    bind = yes
    debug_level = 3
    query_filter = (&amp;(|(mail=%s)(mailAlternateAddress=%s)))
    result_attribute = uid 


########ldap_virtual_users.cf########

    server_host = ldap://localhost
        version = 3
        search_base = &lt;ldap_base_dn&gt;
        bind_dn = &lt;ldap_bind_dn&gt;
        bind_pw = &lt;ldap_bind_password&gt;
        bind = yes
        debug_level = 3
    query_filter = (&amp;(|(mail=%s)(mailAlternateAddress=%s)))
    result_attribute = uid
    result_format = %s/Maildir/


########ldap_senders.cf########

    server_host = ldap://localhost
        version = 3
        search_base = &lt;ldap_base_dn&gt;
        bind_dn = &lt;ldap_bind_dn&gt;
        bind_pw = &lt;ldap_bind_password&gt;
        bind = yes
        debug_level = 3
        query_filter = (&amp;(|(mail=%s)(mailAlternateAddress=%s)))            
    result_attribute = uid
</code></pre>

<p>Now we need to allow dovecot for delivery, so we need to add the following entry to <strong>master.cf</strong></p>

<pre><code>dovecot   unix  -       n       n       -       -       pipe
    flags=DRhu user=vmail:vmail argv=/usr/lib/dovecot/deliver -f ${sender} -d ${recipient}
</code></pre>

<p>I&#8217;m using recipient email id completely as the delivery option, because, in the multi domain setup, ifthere exist two different user&#8217;s with same name say &#8220;abc&#8221;, LDAP dn is always unique, so we cannot have same user name for two different user&#8217;s, in such cases, we uses the full email id as the username for the second user, so in such scenario, we cannot use the user parameter as delivery option, because the it dovecot will remove the @domain part and takes the rest as the user, so if we use full email id, it will not deliver to the actual user.</p>

<p>This setup has worked perfectly with Debian Squeeze and as well as Debian Vagrant Boxes. I&#8217;m writing a puppet module which will automate LDAP,Postfix and Dovecot installation and configuration and will have a ready to use mail server. Soon i will upload it into my <a href="http://github.com/deepakmdass88">github</a> account.</p>
</div>
  
  


</div>

      </article>
    
    </div>
      <div class="row">
        <ul class="pager">
          
            <li class="previous">
              <a href="/blog/page/3/">&larr; Older</a>
            </li>
          
          
            <li class="next">
              <a class="next" href="/">Newer &rarr;</a>
            </li>
          
        </ul>
      </div>
  </div>
</div>


  <div id="footer-widgets">
  <div class="container">
    <div class="row">
  <div class="span3">
    <h2>recent posts</h2>
    <ul class="recent_posts">
      
        <li>
          <a href="/blog/2013/09/22/tweetgrabber-a-live-tweet-grabber/">TweetGrabber - A Live Tweet Grabber</a>
        </li>
      
        <li>
          <a href="/blog/2013/09/19/couchdb-nosql-db-with-a-powerfull-rest-api/">CouchDB -  A NoSQL DB with a Powerfull Rest API</a>
        </li>
      
        <li>
          <a href="/blog/2013/06/27/real-time-web-monitoring-using-lumberjack-logstash-statsd-graphite/">Real Time Web-Monitoring using Lumberjack-Logstash-Statsd-Graphite</a>
        </li>
      
        <li>
          <a href="/blog/2013/06/25/lumberjack-a-light-weight-log-shipper-for-logstash/">Lumberjack - A Light Weight Log shipper for Logstash </a>
        </li>
      
        <li>
          <a href="/blog/2013/05/28/mcomaster-an-html5-based-gui-for-mcollective-with-redis-discovery-method/">McoMaster - An HTML5 based GUI for Mcollective with Redis Discovery Method</a>
        </li>
      
    </ul>
    <h2><a href="/blog/archives">archives</a></h2>
  </div>
  <div class="span3">
    <h2>instagram</h2>
    <div class="instagram"></div>
    <button id="instabutton" class="btn">more</button>
  </div>
  <div class="span4">
    <h2>twitter</h2>
    <a href="https://twitter.com/deepakmdass88" class="twitter-follow-button" data-show-count="true" data-lang="en">Follow @deepakmdass88</a>
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
    <div class="tweet">
    </div>
  </div>
  <div class="span2">
    <h2>found on</h2>
    <a href="https://github.com/deepakmdass88/" rel="tooltip" title="Github"><img class="social_icon" title="Github" alt="github icon" src="/images/glyphicons_381_github.png"></a>
    <a href="http://www.linkedin.com/pub/deepak-dass/44/54/602" rel="tooltip" title="Linkedin"><img class="social_icon" title="Linkedin" alt="Linkedin icon" src="/images/glyphicons_377_linked_in.png"></a>
    <a href="http://twitter.com/deepakmdass88" rel="tooltip" title="Twitter"><img class="social_icon" title="Twitter" alt="Twitter icon" src="/images/glyphicons_391_twitter_t.png"></a>
    <a href="https://plus.google.com/105770729176086017609/posts" rel="tooltip" title="Google Plus"><img class="social_icon" title="Google Plus" alt="Google Plus icon" src="/images/glyphicons_386_google_plus.png"></a>
    <a href="http://ttp://www.quora.com/Deepak-M-Dass" rel="tooltip" title="Quora"><img class="social_icon" title="Quora" alt="Quora icon" src="/images/glyphicons_385_quora.png"></a>
    <h2>contact at</h2>
    <a href="mailto:deepakmdass88@gmail.com">deepakmdass88@gmail.com</a>
  </div>
</div>

  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-left">
  <a href="/">Welcome to My Nerd World</a>
  - Copyright &copy; 2013 - Deepak M Das
</p>
<p class="pull-right">
  Powered by <a href="http://octopress.org/">Octopress</a>. Designed by <a href="http://www.AdrianArtiles.com">Adrian Artiles</a>.
</p>

  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript"></script>
<script>window.jQuery || document.write('<script src="/javascripts/libs/jquery-1.7.2.min.js" type="text/javascript"><\/script>')</script>
<script src="/javascripts/libs/bootstrap.min.js" type="text/javascript"></script>
<script src="/javascripts/jquery.tweet.js" type="text/javascript"></script>
<script src="/javascripts/jquery.instagram.js" type="text/javascript"></script>
<script src="/javascripts/custom.js" type="text/javascript"></script>





</body>
</html>
